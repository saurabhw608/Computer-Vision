{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import getBinaryData, sigmoid, sigmoid_cost, error_rate, relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0 cost: 907.8751994052423 error: 0.519\n",
      "i: 100 cost: 667.5915214736713 error: 0.431\n",
      "i: 200 cost: 649.3395538601296 error: 0.393\n",
      "i: 300 cost: 639.8385758571776 error: 0.369\n",
      "i: 400 cost: 632.0090405309058 error: 0.361\n",
      "i: 500 cost: 624.7495642287267 error: 0.361\n",
      "i: 600 cost: 617.6699455518261 error: 0.354\n",
      "i: 700 cost: 610.6422743556225 error: 0.348\n",
      "i: 800 cost: 603.6538415783082 error: 0.345\n",
      "i: 900 cost: 596.7091023699525 error: 0.341\n",
      "i: 1000 cost: 589.7532763395357 error: 0.341\n",
      "i: 1100 cost: 582.7830654582108 error: 0.331\n",
      "i: 1200 cost: 575.80502279928 error: 0.323\n",
      "i: 1300 cost: 568.8013894047479 error: 0.317\n",
      "i: 1400 cost: 561.744569606612 error: 0.306\n",
      "i: 1500 cost: 554.6147670557027 error: 0.301\n",
      "i: 1600 cost: 547.405986090305 error: 0.297\n",
      "i: 1700 cost: 540.1205568760452 error: 0.294\n",
      "i: 1800 cost: 532.7592194980574 error: 0.288\n",
      "i: 1900 cost: 525.3169194531662 error: 0.281\n",
      "i: 2000 cost: 517.7831036208745 error: 0.275\n",
      "i: 2100 cost: 510.14259891105155 error: 0.261\n",
      "i: 2200 cost: 502.37963412073356 error: 0.256\n",
      "i: 2300 cost: 494.4826009287639 error: 0.246\n",
      "i: 2400 cost: 486.44656980837635 error: 0.241\n",
      "i: 2500 cost: 478.27467888775027 error: 0.238\n",
      "i: 2600 cost: 469.98060971531174 error: 0.232\n",
      "i: 2700 cost: 461.5912049758738 error: 0.232\n",
      "i: 2800 cost: 453.14381175971494 error: 0.229\n",
      "i: 2900 cost: 444.6763485753471 error: 0.225\n",
      "i: 3000 cost: 436.2177986850618 error: 0.217\n",
      "i: 3100 cost: 427.7850016380612 error: 0.216\n",
      "i: 3200 cost: 419.38359038254777 error: 0.209\n",
      "i: 3300 cost: 411.0113277899494 error: 0.203\n",
      "i: 3400 cost: 402.66428653248187 error: 0.199\n",
      "i: 3500 cost: 394.3438786952545 error: 0.193\n",
      "i: 3600 cost: 386.0602182278181 error: 0.187\n",
      "i: 3700 cost: 377.8297986222318 error: 0.175\n",
      "i: 3800 cost: 369.67094350813403 error: 0.168\n",
      "i: 3900 cost: 361.60103838921094 error: 0.161\n",
      "i: 4000 cost: 353.63561921721725 error: 0.159\n",
      "i: 4100 cost: 345.7877182202759 error: 0.152\n",
      "i: 4200 cost: 338.06703036006445 error: 0.146\n",
      "i: 4300 cost: 330.4794477370463 error: 0.143\n",
      "i: 4400 cost: 323.0277420430973 error: 0.139\n",
      "i: 4500 cost: 315.71353239878454 error: 0.137\n",
      "i: 4600 cost: 308.5389427313004 error: 0.136\n",
      "i: 4700 cost: 301.5067619835622 error: 0.131\n",
      "i: 4800 cost: 294.61991459367687 error: 0.121\n",
      "i: 4900 cost: 287.88101646253847 error: 0.116\n",
      "i: 5000 cost: 281.2919750679915 error: 0.115\n",
      "i: 5100 cost: 274.8535515454534 error: 0.11\n",
      "i: 5200 cost: 268.5650861649964 error: 0.105\n",
      "i: 5300 cost: 262.424705784651 error: 0.099\n",
      "i: 5400 cost: 256.4301452012113 error: 0.096\n",
      "i: 5500 cost: 250.57985276111322 error: 0.095\n",
      "i: 5600 cost: 244.8736642415045 error: 0.088\n",
      "i: 5700 cost: 239.31252445434086 error: 0.086\n",
      "i: 5800 cost: 233.89744541266143 error: 0.08\n",
      "i: 5900 cost: 228.62839051448566 error: 0.078\n",
      "i: 6000 cost: 223.503647070959 error: 0.078\n",
      "i: 6100 cost: 218.5198048426432 error: 0.077\n",
      "i: 6200 cost: 213.67214237616759 error: 0.073\n",
      "i: 6300 cost: 208.9551623463563 error: 0.07\n",
      "i: 6400 cost: 204.3631066817561 error: 0.069\n",
      "i: 6500 cost: 199.8903881377587 error: 0.069\n",
      "i: 6600 cost: 195.53193016735207 error: 0.067\n",
      "i: 6700 cost: 191.2834143695164 error: 0.065\n",
      "i: 6800 cost: 187.14142563742078 error: 0.063\n",
      "i: 6900 cost: 183.10348373250653 error: 0.059\n",
      "i: 7000 cost: 179.16796267025717 error: 0.059\n",
      "i: 7100 cost: 175.33387418113284 error: 0.056\n",
      "i: 7200 cost: 171.60122465086053 error: 0.054\n",
      "i: 7300 cost: 167.98862426153465 error: 0.052\n",
      "i: 7400 cost: 163.48372763804167 error: 0.047\n",
      "i: 7500 cost: 157.1073262447705 error: 0.054\n",
      "i: 7600 cost: 154.75282023887792 error: 0.054\n",
      "i: 7700 cost: 151.0257424585153 error: 0.052\n",
      "i: 7800 cost: 149.5048787677756 error: 0.052\n",
      "i: 7900 cost: 149.00992774323564 error: 0.046\n",
      "i: 8000 cost: 147.4521607645617 error: 0.046\n",
      "i: 8100 cost: 147.10678454738843 error: 0.048\n",
      "i: 8200 cost: 157.3562363773225 error: 0.052\n",
      "i: 8300 cost: 347.6325349457764 error: 0.128\n",
      "i: 8400 cost: 136.3497913840797 error: 0.049\n",
      "i: 8500 cost: 135.96258600542245 error: 0.047\n",
      "i: 8600 cost: 135.16463052854087 error: 0.044\n",
      "i: 8700 cost: 138.0676917937057 error: 0.047\n",
      "i: 8800 cost: 129.55547496163237 error: 0.045\n",
      "i: 8900 cost: 130.43596579424192 error: 0.047\n",
      "i: 9000 cost: 132.07113083982864 error: 0.043\n",
      "i: 9100 cost: 126.56780872652435 error: 0.042\n",
      "i: 9200 cost: 126.76002092825468 error: 0.043\n",
      "i: 9300 cost: 126.86318968506774 error: 0.044\n",
      "i: 9400 cost: 121.27564406001763 error: 0.039\n",
      "i: 9500 cost: 116.23179062123279 error: 0.031\n",
      "i: 9600 cost: 114.33837267379883 error: 0.031\n",
      "i: 9700 cost: 112.69175252658984 error: 0.029\n",
      "i: 9800 cost: 111.14220803377899 error: 0.029\n",
      "i: 9900 cost: 109.6634920959717 error: 0.03\n",
      "best error: 0.029\n"
     ]
    }
   ],
   "source": [
    "class ANN(object):\n",
    "    def __init__(self, M):\n",
    "        self.M = M\n",
    "        \n",
    "    def fit(self, X, Y, learning_rate = 5*10e-7, reg = 1.0, epochs = 10000, show_fig = False):\n",
    "        X, Y = shuffle(X,Y)\n",
    "        Xvalid, Yvalid = X[-1000:], Y[-1000:]\n",
    "        X, Y = X[:-1000], Y[:-1000]\n",
    "        \n",
    "        N, D = X.shape\n",
    "        self.W1 = np.random.randn(D, self.M)/ np.sqrt( D + self.M)\n",
    "        self.b1 = np.zeros(self.M)\n",
    "        self.W2 = np.random.randn(self.M)/np.sqrt(self.M)\n",
    "        self.b2 = 0\n",
    "        \n",
    "        costs = []\n",
    "        best_validation_error = 1\n",
    "        for i in range(epochs):\n",
    "            pY, Z = self.forward(X)\n",
    "            \n",
    "            # gradient descent step\n",
    "            pY_Y = pY -Y # pred - target\n",
    "            self.W2 -= learning_rate*(Z.T.dot(pY-Y) + reg*self.W2)  # gradient descent + lasso (l1) regularization\n",
    "            self.b2 -= learning_rate*((pY-Y).sum() + reg*self.b2)\n",
    "            \n",
    "            dZ = np.outer(pY_Y, self.W2) * (1 - Z*Z)  # backprop for tanh function\n",
    "            self.W1 -= learning_rate*(X.T.dot(dZ) + reg*self.W1)\n",
    "            self.b1 -= learning_rate*(np.sum(dZ, axis = 0) + reg*self.b1)\n",
    "            \n",
    "            if i%100 == 0:\n",
    "                pYvalid,_ = self.forward(Xvalid)\n",
    "                c = sigmoid_cost(Yvalid, pYvalid)\n",
    "                costs.append(c)\n",
    "                e = error_rate(Yvalid, np.round(pYvalid))\n",
    "                print(\"i:\",i,\"cost:\",c,\"error:\",e)\n",
    "                if e<best_validation_error:\n",
    "                    best_validation_error = e\n",
    "        print(\"best error:\",best_validation_error)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        # Z = relu(X.dot(self.W1) + self.b1)\n",
    "        Z = np.tanh(X.dot(self.W1) + self.b1)\n",
    "        return sigmoid(Z.dot(self.W2) + self.b2), Z\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        pY = self.forward(X)\n",
    "        return np.round(pY)\n",
    "\n",
    "\n",
    "    def score(self, X, Y):\n",
    "        prediction = self.predict(X)\n",
    "        return 1 - error_rate(Y, prediction)\n",
    "\n",
    "\n",
    "def main():\n",
    "    X, Y = getBinaryData()\n",
    "\n",
    "    X0 = X[Y==0, :]\n",
    "    X1 = X[Y==1, :]\n",
    "    X1 = np.repeat(X1, 9, axis=0)\n",
    "    X = np.vstack([X0, X1])\n",
    "    Y = np.array([0]*len(X0) + [1]*len(X1))\n",
    "    \n",
    "    model = ANN(100)\n",
    "    model.fit(X, Y, show_fig=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
